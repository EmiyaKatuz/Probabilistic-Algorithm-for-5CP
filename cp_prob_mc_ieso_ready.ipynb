{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4338b793",
   "metadata": {},
   "source": [
    "# Coincident Peak Probability via Monte Carlo — IESO (RTO 1‑day‑ahead)\n",
    "\n",
    "Implementing the **Monte Carlo + Adaptive Threshold** Reproduction Pipeline of Carmona et al. (2024)\n",
    "\n",
    "1. Make residuals: For each hour h, take the historical actual−forecast.\n",
    "\n",
    "2. Edge trimming: Fit the tail of GPD (generalized Pareto) individually every hour, map the residuals to [0,1] using probability integral transform (PIT), and then use the standard normal quantile function Q^-1 to turn it into the \"Gaussianized residual\" of standard normal N(0,1).\n",
    "\n",
    "3. Graphical model: Splice the 24-hour \"Gaussian residual\" into a 24-dimensional vector, assuming its joint distribution is multivariate normal, use Graphical LASSO (maximum likelihood with regularity) to estimate the accuracy matrix/covariance to get the sparse dependence structure between hours.\n",
    "\n",
    "4. Monte Carlo: From the 24-dimensional Gauss learned, took Gauss residuals → used the previous inverse transformation to restore to the residuals of the original dimension → added back to the previous curve to get the complete set of scenes of \"Tomorrow 24 hours.\"\n",
    "\n",
    "5. Calculate the probability:\n",
    "\n",
    "1CP Probability: The \"Tomorrow's Sun Peak\" in the scene exceeds the \"running to yesterday's largest peak in the year\".\n",
    "\n",
    "Top-5 Update probability: The ratio exceeds the \"run to yesterday's previous k threshold.\"\n",
    "\n",
    "4CP probability: In June–9, the \"maximum value of the current month to date\" is used as the benchmark, and the proportion exceeding it in the scenario.\n",
    "\n",
    "Then, it is combined with a simple threshold (such as 0.5) or \"red, orange, yellow and green\" grading to serve as an alarm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b9237a",
   "metadata": {},
   "source": "## 0. Environment Setup"
  },
  {
   "cell_type": "code",
   "id": "35a0b959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T18:29:28.980159Z",
     "start_time": "2025-08-28T18:29:27.729150Z"
    }
   },
   "source": [
    "# ==== Cell 0: Environment ====\n",
    "import os, warnings, math, datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Optional, Tuple, List\n",
    "from scipy import stats\n",
    "from sklearn.covariance import GraphicalLassoCV\n",
    "from sklearn.metrics import precision_recall_fscore_support, brier_score_loss, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "np.random.seed(42)\n",
    "\n",
    "try:\n",
    "    from statsmodels.distributions.empirical_distribution import ECDF\n",
    "except Exception:\n",
    "    class ECDF:\n",
    "        def __init__(self, x):\n",
    "            x = np.asarray(x)\n",
    "            x = x[np.isfinite(x)]\n",
    "            self.x = np.sort(x)\n",
    "            self.n = len(self.x)\n",
    "\n",
    "        def __call__(self, v):\n",
    "            v = np.asarray(v)\n",
    "            return np.searchsorted(self.x, v, side=\"right\") / max(self.n, 1)\n",
    "\n",
    "print(\"pandas:\", pd.__version__)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 2.2.3\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "6aa39c84",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Data Reading (IESO)\n",
    "- File: `/mnt/data/IESO-Ontario Demand 2022-2025 1 day ahead.csv`\n",
    "- Columns: `ECA ... Forecast`, `RTO ... Forecast`, `TESLA ... Forecast`, `TESLA ... Actual`\n",
    "- The default selection of `RTO`\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4920325e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T18:29:28.987421Z",
     "start_time": "2025-08-28T18:29:28.984258Z"
    }
   },
   "source": [
    "# ==== Cell 1: Parameters ====\n",
    "PATH = \"IESO-Ontario Demand 2022-2025 1 day ahead.csv\"\n",
    "\n",
    "FORECAST_SOURCES = [\"ECA\", \"RTO\", \"TESLA\"]\n",
    "\n",
    "# Monte Carlo Sample number and window\n",
    "LAST_DAYS = 730  # None = full amount; it is recommended to zoom in the first 365~730\n",
    "N_SIMS = 2000  # 600 starts, 2000+ is more stable\n",
    "\n",
    "BUDGET_1CP = 6\n",
    "BUDGET_TOP5 = 12\n",
    "BUDGET_4CP_SUMMER = 8  # Total summer budget (June-September)\n",
    "\n",
    "SAVE_OUTPUTS = True\n",
    "OUT_DIR = \"./output_cp_prob_mc_ieso\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T18:29:29.032817Z",
     "start_time": "2025-08-28T18:29:29.011930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== Cell 2: Load CSV & detect columns ====\n",
    "assert os.path.exists(PATH), f\"Data file not found: {PATH}\"\n",
    "raw = pd.read_csv(PATH)\n",
    "\n",
    "# Automatically identify columns\n",
    "all_cols = raw.columns.tolist()\n",
    "FCAST_COLS = [c for c in all_cols if \"Historic Forecast\" in c]\n",
    "ACTUAL_CANDIDATES = [c for c in all_cols if \"Actual\" in c]\n",
    "\n",
    "assert len(FCAST_COLS) >= 1, \"The *Historic Forecast* column was not found, please check the file.\"\n",
    "assert len(ACTUAL_CANDIDATES) >= 1, \"The *Actual* column was not found, please check the file.\"\n",
    "\n",
    "ACTUAL_COL = ACTUAL_CANDIDATES[0]\n",
    "\n",
    "print(\"Forecast columns:\", FCAST_COLS)\n",
    "print(\"Actual column:\", ACTUAL_COL)\n",
    "print(raw.head(3))\n"
   ],
   "id": "2866957ed2408140",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast columns: ['ECA: IESO-Ontario Demand Historic Forecast', 'RTO: IESO-Ontario Demand Historic Forecast', 'TESLA: IESO-Ontario Demand Historic Forecast']\n",
      "Actual column: TESLA: IESO-Ontario Demand Actual\n",
      "        Date  Time  ECA: IESO-Ontario Demand Historic Forecast  \\\n",
      "0  1/01/2022  1:00                                     13589.5   \n",
      "1  1/01/2022  2:00                                     13104.1   \n",
      "2  1/01/2022  3:00                                     12681.4   \n",
      "\n",
      "   RTO: IESO-Ontario Demand Historic Forecast  \\\n",
      "0                                     13521.8   \n",
      "1                                     13079.0   \n",
      "2                                     12677.8   \n",
      "\n",
      "   TESLA: IESO-Ontario Demand Historic Forecast  \\\n",
      "0                                       13521.8   \n",
      "1                                       13079.0   \n",
      "2                                       12677.8   \n",
      "\n",
      "   TESLA: IESO-Ontario Demand Actual  \n",
      "0                           13542.75  \n",
      "1                           13253.67  \n",
      "2                           12683.29  \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T18:29:34.366493Z",
     "start_time": "2025-08-28T18:29:29.037506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== Cell 3: Timestamp parser (handles '24:00') ====\n",
    "def parse_timestamp(date_str, time_str):\n",
    "    t = str(time_str).strip()\n",
    "    if t.startswith(\"24:\"):\n",
    "        dt0 = dt.datetime.strptime(str(date_str).strip(), \"%d/%m/%Y\") + dt.timedelta(days=1)\n",
    "        parts = t.split(\":\")\n",
    "        mm = parts[1] if len(parts) >= 2 else \"00\"\n",
    "        ss = parts[2] if len(parts) == 3 else \"00\"\n",
    "        return pd.to_datetime(f\"{dt0.strftime('%d/%m/%Y')} 00:{mm}:{ss}\", dayfirst=True)\n",
    "    return pd.to_datetime(f\"{date_str} {time_str}\", dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "\n",
    "ts = [parse_timestamp(d, t) for d, t in zip(raw[\"Date\"], raw[\"Time\"])]\n",
    "ts = pd.to_datetime(ts)\n",
    "assert pd.isna(ts).sum() == 0, \"The time stamp parsing exists NaT, please check the 'Date'/'Time' format.\"\n",
    "print(\"Time range:\", ts.min(), \"→\", ts.max(), \"len:\", len(ts))\n"
   ],
   "id": "82bf6d5fd0e809b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time range: 2022-01-01 01:00:00 → 2025-05-16 00:00:00 len: 29543\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T18:29:34.456174Z",
     "start_time": "2025-08-28T18:29:34.429101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== Cell 4 (fixed): Safe hourly regularization + base builder ====\n",
    "def hourly_regularize_safe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out_parts = []\n",
    "    for (src, zn), g in df.groupby(['forecast_src', 'zone'], sort=False):\n",
    "        g = g.sort_values('timestamp')\n",
    "        g2 = g.set_index('timestamp').asfreq('H')\n",
    "        # Only fill numeric columns to avoid object column participation\n",
    "        num_cols = [c for c in g2.columns if pd.api.types.is_numeric_dtype(g2[c])]\n",
    "        g2[num_cols] = g2[num_cols].ffill().bfill()\n",
    "        g2 = g2.reset_index()\n",
    "        g2['forecast_src'] = src\n",
    "        g2['zone'] = zn\n",
    "        out_parts.append(g2)\n",
    "    out = pd.concat(out_parts, ignore_index=True)\n",
    "    out = out.sort_values('timestamp').reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_base_df(forecast_col: str) -> pd.DataFrame:\n",
    "    df = pd.DataFrame({\n",
    "        \"timestamp\": ts,\n",
    "        \"zone\": \"IESO\",\n",
    "        \"actual_mw\": pd.to_numeric(raw[ACTUAL_COL], errors=\"coerce\"),\n",
    "        \"da_forecast_mw\": pd.to_numeric(raw[forecast_col], errors=\"coerce\"),\n",
    "        \"forecast_src\": forecast_col.split(\":\")[0].strip()\n",
    "    }).dropna().sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "    # Merge DST callback repeat hours (take the mean of the same hour)\n",
    "    df = df.groupby(['forecast_src', 'zone', 'timestamp'], as_index=False) \\\n",
    "        .agg({'actual_mw': 'mean', 'da_forecast_mw': 'mean'})\n",
    "\n",
    "    df = hourly_regularize_safe(df)\n",
    "    df = df.dropna(subset=['actual_mw', 'da_forecast_mw']).sort_values('timestamp').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "_test_col = FCAST_COLS[0]\n",
    "_df_test = build_base_df(_test_col)\n",
    "print(_test_col, _df_test.shape)\n",
    "print(_df_test[['timestamp', 'zone', 'forecast_src', 'actual_mw', 'da_forecast_mw']].head(3))\n"
   ],
   "id": "9feda8323cc55284",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECA: IESO-Ontario Demand Historic Forecast (29536, 5)\n",
      "            timestamp  zone forecast_src  actual_mw  da_forecast_mw\n",
      "0 2022-01-01 01:00:00  IESO          ECA   13542.75         13589.5\n",
      "1 2022-01-01 02:00:00  IESO          ECA   13253.67         13104.1\n",
      "2 2022-01-01 03:00:00  IESO          ECA   12683.29         12681.4\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "a9b8325d",
   "metadata": {},
   "source": "## 2. Construct the daily matrix and tags (1CP/Top‑5)"
  },
  {
   "cell_type": "code",
   "id": "3f1e9cea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T18:29:34.469993Z",
     "start_time": "2025-08-28T18:29:34.463734Z"
    }
   },
   "source": [
    "# ==== NEW (REPLACE your daily-label cell): Hourly thresholds with PJM summer reset ====\n",
    "def build_hourly_features(df_base: pd.DataFrame) -> pd.DataFrame:\n",
    "    x = df_base.copy()\n",
    "    x[\"date\"] = x[\"timestamp\"].dt.floor(\"D\")\n",
    "    x[\"year\"] = x[\"timestamp\"].dt.year\n",
    "    x[\"month\"] = x[\"timestamp\"].dt.month\n",
    "    x[\"hour\"] = x[\"timestamp\"].dt.hour\n",
    "    x[\"residual\"] = x[\"actual_mw\"] - x[\"da_forecast_mw\"]\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_hourly_matrix(features_hourly: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Turn hourly residuals into a 24-dim row per *day* for modeling.\"\"\"\n",
    "    mat = features_hourly.pivot_table(index=\"date\", columns=\"hour\",\n",
    "                                      values=\"residual\", aggfunc=\"mean\")\n",
    "    for h in range(24):\n",
    "        if h not in mat.columns: mat[h] = np.nan\n",
    "    mat = mat[[h for h in range(24)]].sort_index()\n",
    "    mat.columns = [f\"res_h{h:02d}\" for h in range(24)]\n",
    "    # attach year/month for each date (from any hour of that day)\n",
    "    ym = features_hourly.groupby(\"date\")[[\"year\", \"month\"]].first()\n",
    "    mat = mat.merge(ym, left_index=True, right_index=True, how=\"left\")\n",
    "    mat = mat.dropna(subset=[f\"res_h{h:02d}\" for h in range(24)]).reset_index()  # keep date col\n",
    "    return mat  # columns: date, res_h00..res_h23, year, month\n",
    "\n",
    "\n",
    "def compute_pjm_summer_thresholds_hourly(df_base: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each *day*, compute thresholds using *hourly actuals* seen up to yesterday,\n",
    "    within PJM summer (Jun–Sep) and reset each year on Jun 1.\n",
    "    Returns: DataFrame indexed by date with columns:\n",
    "      - summer_running_max_prev_hourly\n",
    "      - summer_top5_thr_prev_hourly\n",
    "      - is_summer_day (flag for Jun–Sep)\n",
    "    \"\"\"\n",
    "    x = df_base.copy()\n",
    "    x[\"date\"] = x[\"timestamp\"].dt.floor(\"D\")\n",
    "    x[\"year\"] = x[\"timestamp\"].dt.year\n",
    "    x[\"month\"] = x[\"timestamp\"].dt.month\n",
    "    x[\"is_summer\"] = x[\"month\"].isin([6, 7, 8, 9])\n",
    "\n",
    "    # prepare container per date\n",
    "    dates = np.sort(x[\"date\"].unique())\n",
    "    recs = []\n",
    "\n",
    "    for y, g_year in x.groupby(\"year\"):\n",
    "        g_sum = g_year[g_year[\"is_summer\"]].sort_values(\"timestamp\")\n",
    "        if g_sum.empty:\n",
    "            # still return records for dates in this year with NaNs\n",
    "            for d in np.sort(g_year[\"date\"].unique()):\n",
    "                recs.append({\"date\": d, \"summer_running_max_prev_hourly\": np.nan,\n",
    "                             \"summer_top5_thr_prev_hourly\": np.nan,\n",
    "                             \"is_summer_day\": bool(int(pd.Timestamp(d).month in [6, 7, 8, 9]))})\n",
    "            continue\n",
    "\n",
    "        # iterate summer dates of this year in order\n",
    "        for d in np.sort(g_year[\"date\"].unique()):\n",
    "            is_summer_day = int(pd.Timestamp(d).month in [6, 7, 8, 9])\n",
    "            if not is_summer_day:\n",
    "                recs.append({\"date\": d, \"summer_running_max_prev_hourly\": np.nan,\n",
    "                             \"summer_top5_thr_prev_hourly\": np.nan, \"is_summer_day\": False})\n",
    "                continue\n",
    "\n",
    "            # only use hours strictly before this date (up to yesterday)\n",
    "            prior_hours = g_sum[g_sum[\"date\"] < d][\"actual_mw\"].values\n",
    "            if len(prior_hours) == 0:\n",
    "                recs.append({\"date\": d, \"summer_running_max_prev_hourly\": np.nan,\n",
    "                             \"summer_top5_thr_prev_hourly\": np.nan, \"is_summer_day\": True})\n",
    "                continue\n",
    "\n",
    "            M_prev = float(np.max(prior_hours))\n",
    "            if len(prior_hours) >= 5:\n",
    "                kth = np.partition(prior_hours, -5)[-5]  # 5th highest so far\n",
    "            else:\n",
    "                kth = np.nan\n",
    "\n",
    "            recs.append({\"date\": d,\n",
    "                         \"summer_running_max_prev_hourly\": M_prev,\n",
    "                         \"summer_top5_thr_prev_hourly\": float(kth),\n",
    "                         \"is_summer_day\": True})\n",
    "\n",
    "    thr = pd.DataFrame(recs).set_index(\"date\").sort_index()\n",
    "    return thr\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "d59f4230",
   "metadata": {},
   "source": "## 3. Edge Gauss + Graphical LASSO (Related within the day)"
  },
  {
   "cell_type": "code",
   "id": "472ad286",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T18:29:34.497270Z",
     "start_time": "2025-08-28T18:29:34.489533Z"
    }
   },
   "source": [
    "# ==== Cell 6 (REPLACE): Paper-consistent upper-tail POT-GPD marginals ====\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import genpareto, norm\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MarginalPOT:\n",
    "    hour: int\n",
    "    p_u: float  # upper-tail threshold quantile (e.g., 0.90)\n",
    "    u: float  # threshold value at p_u\n",
    "    xi: float  # GPD shape\n",
    "    beta: float  # GPD scale ( >0 )\n",
    "    center_vals: np.ndarray  # sorted residuals in (-inf, u], used as ECDF in body\n",
    "\n",
    "    # piecewise CDF: body via ECDF, upper tail via GPD (POT)\n",
    "    def cdf(self, x: np.ndarray) -> np.ndarray:\n",
    "        x = np.asarray(x, dtype=float)\n",
    "        u = np.empty_like(x)\n",
    "\n",
    "        # body: x <= u  --> map by ECDF to [0, p_u]\n",
    "        mask_body = x <= self.u\n",
    "        if mask_body.any():\n",
    "            vals = self.center_vals\n",
    "            ranks = np.searchsorted(vals, x[mask_body], side=\"right\")\n",
    "            h = np.clip(ranks / max(len(vals), 1), 0.0, 1.0)  # ECDF in [0,1]\n",
    "            u[mask_body] = self.p_u * h  # scale to [0, p_u]\n",
    "\n",
    "        # upper tail: x > u  --> POT: F(x) = p_u + (1-p_u) * GPD(x-u)\n",
    "        mask_tail = ~mask_body\n",
    "        if mask_tail.any():\n",
    "            y = np.maximum(x[mask_tail] - self.u, 0.0)\n",
    "            # GPD CDF on exceedances y\n",
    "            if self.beta <= 0:\n",
    "                g = 1.0 - np.exp(-y / (np.std(self.center_vals) + 1e-6))  # fallback\n",
    "            else:\n",
    "                g = genpareto.cdf(y, c=self.xi, loc=0.0, scale=self.beta)\n",
    "            u[mask_tail] = self.p_u + (1.0 - self.p_u) * g\n",
    "\n",
    "        return np.clip(u, 1e-9, 1 - 1e-9)\n",
    "\n",
    "    # piecewise PPF: invert cdf()\n",
    "    def ppf(self, u: np.ndarray) -> np.ndarray:\n",
    "        u = np.asarray(u, dtype=float)\n",
    "        x = np.empty_like(u)\n",
    "\n",
    "        # body: 0 <= u <= p_u  --> inverse-ECDF on center_vals\n",
    "        mask_body = u <= self.p_u\n",
    "        if mask_body.any():\n",
    "            vals = self.center_vals\n",
    "            q = np.where(self.p_u > 0, u[mask_body] / self.p_u, 0.0)  # [0,1]\n",
    "            idx = np.clip((q * (len(vals) - 1)).astype(int), 0, max(len(vals) - 1, 0))\n",
    "            x[mask_body] = vals[idx]\n",
    "\n",
    "        # tail: u > p_u  --> u = p_u + (1-p_u)*GPD(y) => GPD(y) = (u-p_u)/(1-p_u)\n",
    "        mask_tail = ~mask_body\n",
    "        if mask_tail.any():\n",
    "            q = np.clip((u[mask_tail] - self.p_u) / (1.0 - self.p_u), 0.0, 1.0)\n",
    "            if self.beta <= 0:\n",
    "                lam = 1.0 / (np.std(self.center_vals) + 1e-6)\n",
    "                y = -np.log(np.clip(1.0 - q, 1e-12, 1.0)) / lam\n",
    "            else:\n",
    "                y = genpareto.ppf(q, c=self.xi, loc=0.0, scale=self.beta)\n",
    "            x[mask_tail] = self.u + np.maximum(y, 0.0)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # wrappers used downstream\n",
    "    def to_normal(self, x: np.ndarray) -> np.ndarray:\n",
    "        return norm.ppf(self.cdf(x))\n",
    "\n",
    "    def from_normal(self, z: np.ndarray) -> np.ndarray:\n",
    "        return self.ppf(norm.cdf(z))\n",
    "\n",
    "\n",
    "def fit_marginals_pot(features: pd.DataFrame,\n",
    "                      p_u: float = 0.90,\n",
    "                      min_tail_n: int = 50) -> Dict[int, MarginalPOT]:\n",
    "    \"\"\"\n",
    "    Paper-consistent POT-GPD on the *upper tail* per hour.\n",
    "    Body (<= u) uses ECDF to map to [0, p_u]; tail (> u) uses GPD to map to (p_u, 1].\n",
    "    \"\"\"\n",
    "    out: Dict[int, MarginalPOT] = {}\n",
    "    for h in range(24):\n",
    "        vals = features[f\"res_h{h:02d}\"].values.astype(float)\n",
    "        vals = vals[np.isfinite(vals)]\n",
    "        vals_sorted = np.sort(vals)\n",
    "\n",
    "        # threshold at p_u (e.g., 90% quantile)\n",
    "        u = float(np.quantile(vals_sorted, p_u))\n",
    "        body = vals_sorted[vals_sorted <= u]\n",
    "        exc = vals_sorted[vals_sorted > u] - u\n",
    "\n",
    "        # GPD fit (exceedances)\n",
    "        if len(exc) >= min_tail_n:\n",
    "            try:\n",
    "                xi, loc, beta = genpareto.fit(exc, floc=0.0)\n",
    "                beta = float(max(beta, 1e-9))\n",
    "            except Exception:\n",
    "                xi, beta = 0.0, float(np.std(exc) + 1e-6)\n",
    "        else:\n",
    "            # tail too short -> robust fallback\n",
    "            xi, beta = 0.0, float(np.std(exc) + 1e-6) if len(exc) else 0.0\n",
    "\n",
    "        out[h] = MarginalPOT(\n",
    "            hour=h, p_u=p_u, u=u,\n",
    "            xi=float(xi), beta=float(beta),\n",
    "            center_vals=body if len(body) else vals_sorted\n",
    "        )\n",
    "    return out\n",
    "\n",
    "\n",
    "def gaussianize(features: pd.DataFrame, transforms: Dict[int, MarginalPOT]) -> np.ndarray:\n",
    "    Z = np.zeros((len(features), 24))\n",
    "    it = features.itertuples(index=False)\n",
    "    for i, row in enumerate(it):\n",
    "        for h in range(24):\n",
    "            Z[i, h] = transforms[h].to_normal(np.array([getattr(row, f\"res_h{h:02d}\")]))[0]\n",
    "    return Z"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "527a47c3",
   "metadata": {},
   "source": "## 4. Scene generation and CP probability"
  },
  {
   "cell_type": "code",
   "id": "a6f8883d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T18:29:34.507669Z",
     "start_time": "2025-08-28T18:29:34.502130Z"
    }
   },
   "source": [
    "# ==== Cell 7: Scenario generation + probabilities ====\n",
    "def build_daily_forecast_matrix(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    x = df.copy()\n",
    "    x[\"date\"] = x[\"timestamp\"].dt.floor(\"D\")\n",
    "    x[\"hour\"] = x[\"timestamp\"].dt.hour\n",
    "    mat = x.pivot_table(index=\"date\", columns=\"hour\", values=\"da_forecast_mw\", aggfunc=\"mean\")\n",
    "    for h in range(24):\n",
    "        if h not in mat.columns:\n",
    "            mat[h] = np.nan\n",
    "    mat = mat[[h for h in range(24)]].sort_index()\n",
    "    mat.columns = [f\"fh{h:02d}\" for h in range(24)]\n",
    "    return mat\n",
    "\n",
    "\n",
    "def scenario_probabilities_pjm_hourly(df_base: pd.DataFrame,\n",
    "                                      feats_daily24: pd.DataFrame,\n",
    "                                      transforms: Dict[int, MarginalPOT],\n",
    "                                      cov: np.ndarray,\n",
    "                                      n_sims: int = 600,\n",
    "                                      last_days: int | None = 365,\n",
    "                                      return_peak_hour: bool = True) -> pd.DataFrame:\n",
    "    # 24h DA matrix per date\n",
    "    x = df_base.copy()\n",
    "    x[\"date\"] = x[\"timestamp\"].dt.floor(\"D\")\n",
    "    x[\"hour\"] = x[\"timestamp\"].dt.hour\n",
    "    fmat = x.pivot_table(index=\"date\", columns=\"hour\", values=\"da_forecast_mw\", aggfunc=\"mean\")\n",
    "    for h in range(24):\n",
    "        if h not in fmat.columns: fmat[h] = np.nan\n",
    "    fmat = fmat[[h for h in range(24)]].sort_index()\n",
    "    fmat.columns = [f\"fh{h:02d}\" for h in range(24)]\n",
    "\n",
    "    # thresholds with PJM summer reset\n",
    "    thr = compute_pjm_summer_thresholds_hourly(df_base)\n",
    "\n",
    "    # optional evaluation window\n",
    "    if last_days is not None and len(fmat.index) > 0:\n",
    "        cutoff = fmat.index.max() - pd.Timedelta(days=last_days)\n",
    "        fmat = fmat[fmat.index > cutoff]\n",
    "\n",
    "    # MC samples shared across dates\n",
    "    rng = np.random.default_rng(9)\n",
    "    z_all = rng.multivariate_normal(mean=np.zeros(24), cov=cov, size=n_sims)\n",
    "    e_all = np.vstack([transforms[h].from_normal(z_all[:, h]) for h in range(24)]).T\n",
    "\n",
    "    out = []\n",
    "    for date, row in fmat.iterrows():\n",
    "        if date not in thr.index or not bool(thr.loc[date, \"is_summer_day\"]):\n",
    "            continue\n",
    "        fvec = row.values.astype(float)\n",
    "        if not np.isfinite(fvec).all():\n",
    "            continue\n",
    "\n",
    "        sims = fvec.reshape(1, -1) + e_all  # (S,24)\n",
    "        sim_max = sims.max(axis=1)\n",
    "        M_prev = thr.loc[date, \"summer_running_max_prev_hourly\"]\n",
    "        T5_prev = thr.loc[date, \"summer_top5_thr_prev_hourly\"]\n",
    "        p1 = float((sim_max > M_prev).mean()) if np.isfinite(M_prev) else np.nan\n",
    "        p5 = float((sim_max > T5_prev).mean()) if np.isfinite(T5_prev) else np.nan\n",
    "\n",
    "        rec = {\"date\": date,\n",
    "               \"p_1cp_hourly_summer\": p1,\n",
    "               \"p_top5_hourly_summer\": p5}\n",
    "\n",
    "        if return_peak_hour:\n",
    "            peak_idx = np.argmax(sims, axis=1)\n",
    "            ph = np.bincount(peak_idx, minlength=24) / sims.shape[0]\n",
    "            rec.update({f\"ph_{h:02d}\": float(ph[h]) for h in range(24)})\n",
    "            rec[\"peak_hour_mlh\"] = int(np.argmax(ph))  # most likely hour (0-23)\n",
    "\n",
    "        out.append(rec)\n",
    "\n",
    "    prob = pd.DataFrame(out).set_index(\"date\").sort_index()\n",
    "    return prob"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T18:29:34.520588Z",
     "start_time": "2025-08-28T18:29:34.511637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== NEW: 4CP (Monthly Top-4) thresholds & probabilities for summer (Jun–Sep) ====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Dict\n",
    "\n",
    "\n",
    "def compute_summer_monthly_topk_thresholds_hourly(df_base: pd.DataFrame,\n",
    "                                                  k: int = 4) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    对每个夏季月份（6–9 月），构造“到昨日为止，本月第 k 高 *小时*负荷”的运行阈值。\n",
    "    返回：index=date；列：\n",
    "      - m4_hourly_prev (float)   本月 Top-k 的第 k 名阈值（小时口径）\n",
    "      - is_summer_month_day (bool) 本日是否属于夏季月份\n",
    "      - year, month\n",
    "    \"\"\"\n",
    "    x = df_base.copy()\n",
    "    x[\"date\"] = x[\"timestamp\"].dt.floor(\"D\")\n",
    "    x[\"year\"] = x[\"timestamp\"].dt.year\n",
    "    x[\"month\"] = x[\"timestamp\"].dt.month\n",
    "\n",
    "    recs = []\n",
    "    for (y, m), g in x.groupby([\"year\", \"month\"]):\n",
    "        is_summer = (m in [6, 7, 8, 9])\n",
    "        dates = np.sort(g[\"date\"].unique())\n",
    "        # 按本月逐日滚动\n",
    "        for d in dates:\n",
    "            if not is_summer:\n",
    "                recs.append({\"date\": d, \"year\": y, \"month\": m,\n",
    "                             \"m4_hourly_prev\": np.nan, \"is_summer_month_day\": False})\n",
    "                continue\n",
    "            prior = g[g[\"date\"] < d][\"actual_mw\"].values  # 本月到昨日为止的全部小时实测\n",
    "            if len(prior) >= k:\n",
    "                kth = np.partition(prior, -k)[-k]\n",
    "            else:\n",
    "                kth = np.nan\n",
    "            recs.append({\"date\": d, \"year\": y, \"month\": m,\n",
    "                         \"m4_hourly_prev\": float(kth), \"is_summer_month_day\": True})\n",
    "\n",
    "    thr4h = pd.DataFrame(recs).set_index(\"date\").sort_index()\n",
    "    return thr4h\n",
    "\n",
    "\n",
    "def compute_summer_monthly_topk_thresholds_daily(df_base: pd.DataFrame,\n",
    "                                                 k: int = 4) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    对每个夏季月份（6–9 月），构造“到昨日为止，本月第 k 高 *日峰*”的运行阈值。\n",
    "    返回：index=date；列：\n",
    "      - m4_daily_prev (float)    本月 Top-k 的第 k 名阈值（日口径：以每日最高小时作为日峰）\n",
    "      - is_summer_month_day (bool) 本日是否属于夏季月份\n",
    "      - year, month\n",
    "    \"\"\"\n",
    "    x = df_base.copy()\n",
    "    x[\"date\"] = x[\"timestamp\"].dt.floor(\"D\")\n",
    "    x[\"year\"] = x[\"timestamp\"].dt.year\n",
    "    x[\"month\"] = x[\"timestamp\"].dt.month\n",
    "    # 每日“日峰”\n",
    "    day_max = x.groupby([\"year\", \"month\", \"date\"])[\"actual_mw\"].max().rename(\"day_max\").reset_index()\n",
    "\n",
    "    recs = []\n",
    "    for (y, m), g in day_max.groupby([\"year\", \"month\"]):\n",
    "        is_summer = (m in [6, 7, 8, 9])\n",
    "        dates = np.sort(g[\"date\"].values)\n",
    "        for d in dates:\n",
    "            if not is_summer:\n",
    "                recs.append({\"date\": d, \"year\": y, \"month\": m,\n",
    "                             \"m4_daily_prev\": np.nan, \"is_summer_month_day\": False})\n",
    "                continue\n",
    "            prior = g[g[\"date\"] < d][\"day_max\"].values  # 本月到昨日为止的“日峰”序列\n",
    "            if len(prior) >= k:\n",
    "                kth = np.partition(prior, -k)[-k]\n",
    "            else:\n",
    "                kth = np.nan\n",
    "            recs.append({\"date\": d, \"year\": y, \"month\": m,\n",
    "                         \"m4_daily_prev\": float(kth), \"is_summer_month_day\": True})\n",
    "\n",
    "    thr4d = pd.DataFrame(recs).set_index(\"date\").sort_index()\n",
    "    return thr4d\n",
    "\n",
    "\n",
    "def scenario_probabilities_pjm_4cp(df_base: pd.DataFrame,\n",
    "                                   feats_daily24: pd.DataFrame,\n",
    "                                   transforms,\n",
    "                                   cov: np.ndarray,\n",
    "                                   n_sims: int = 600,\n",
    "                                   last_days: Optional[int] = 365,\n",
    "                                   return_peak_hour: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    同一天内同时计算两种 4CP 概率（6–9 月每月 Top-4）：\n",
    "      - 小时口径：p_4cp_hourly_monthlyTop4  = P(明日任一小时 > 本月到昨日为止的第4高“小时”负荷阈值)\n",
    "      - 日口径  ：p_4cp_daily_monthlyTop4   = P(明日日峰   > 本月到昨日为止的第4高“日峰”   阈值)\n",
    "    若 return_peak_hour=True，则附带“最可能峰小时”分布（与小时口径同样的峰时统计）。\n",
    "    \"\"\"\n",
    "    # 24h DA 矩阵\n",
    "    x = df_base.copy()\n",
    "    x[\"date\"] = x[\"timestamp\"].dt.floor(\"D\")\n",
    "    x[\"hour\"] = x[\"timestamp\"].dt.hour\n",
    "    fmat = x.pivot_table(index=\"date\", columns=\"hour\", values=\"da_forecast_mw\", aggfunc=\"mean\")\n",
    "    for h in range(24):\n",
    "        if h not in fmat.columns: fmat[h] = np.nan\n",
    "    fmat = fmat[[h for h in range(24)]].sort_index()\n",
    "    fmat.columns = [f\"fh{h:02d}\" for h in range(24)]\n",
    "\n",
    "    # 4CP 两类阈值（按月 Top-4）\n",
    "    thr4h = compute_summer_monthly_topk_thresholds_hourly(df_base, k=4)\n",
    "    thr4d = compute_summer_monthly_topk_thresholds_daily(df_base, k=4)\n",
    "\n",
    "    # 可选：仅评最近 N 天\n",
    "    if last_days is not None and len(fmat.index) > 0:\n",
    "        cutoff = fmat.index.max() - pd.Timedelta(days=last_days)\n",
    "        fmat = fmat[fmat.index > cutoff]\n",
    "\n",
    "    # 共享 MC 样本\n",
    "    rng = np.random.default_rng(19)\n",
    "    z_all = rng.multivariate_normal(mean=np.zeros(24), cov=cov, size=n_sims)\n",
    "    e_all = np.vstack([transforms[h].from_normal(z_all[:, h]) for h in range(24)]).T  # (S,24)\n",
    "\n",
    "    out = []\n",
    "    for date, row in fmat.iterrows():\n",
    "        # 仅在夏季月份计算\n",
    "        if (date not in thr4h.index) or (date not in thr4d.index) or (not bool(thr4h.loc[date, \"is_summer_month_day\"])):\n",
    "            continue\n",
    "        fvec = row.values.astype(float)\n",
    "        if not np.isfinite(fvec).all():\n",
    "            continue\n",
    "\n",
    "        sims = fvec.reshape(1, -1) + e_all  # (S,24)\n",
    "        sim_hourly_max = sims.max(axis=1)  # “该日任一小时”的最大值（也即当日“日峰”）\n",
    "        # 阈值\n",
    "        H4_prev = thr4h.loc[date, \"m4_hourly_prev\"]\n",
    "        D4_prev = thr4d.loc[date, \"m4_daily_prev\"]\n",
    "        p4h = float((sim_hourly_max > H4_prev).mean()) if np.isfinite(H4_prev) else np.nan\n",
    "        p4d = float((sim_hourly_max > D4_prev).mean()) if np.isfinite(D4_prev) else np.nan\n",
    "\n",
    "        rec = {\"date\": date,\n",
    "               \"p_4cp_hourly_monthlyTop4\": p4h,\n",
    "               \"p_4cp_daily_monthlyTop4\": p4d}\n",
    "        if return_peak_hour:\n",
    "            peak_idx = np.argmax(sims, axis=1)\n",
    "            ph = np.bincount(peak_idx, minlength=24) / sims.shape[0]\n",
    "            rec.update({f\"ph_{h:02d}\": float(ph[h]) for h in range(24)})\n",
    "            rec[\"peak_hour_mlh\"] = int(np.argmax(ph))\n",
    "        out.append(rec)\n",
    "\n",
    "    prob4 = pd.DataFrame(out).set_index(\"date\").sort_index()\n",
    "    return prob4\n"
   ],
   "id": "8f7d1b421ec937ab",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "4764e570",
   "metadata": {},
   "source": "## 5. Adaptive Threshold + Metrics"
  },
  {
   "cell_type": "code",
   "id": "211492eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T18:29:34.529826Z",
     "start_time": "2025-08-28T18:29:34.525187Z"
    }
   },
   "source": [
    "# ==== Cell 8: Adaptive threshold + evaluation ====\n",
    "def adaptive_threshold_series(prob: pd.Series, budget_per_year: int = 10) -> pd.Series:\n",
    "    # Given quantile thresholds based on budget, the warm-up of the first 15 days is NaN\n",
    "    q = 1.0 - (budget_per_year / 365.0)\n",
    "    thresholds, hist = [], []\n",
    "    for v in prob.values:\n",
    "        if len(hist) < 15:\n",
    "            thresholds.append(np.nan)\n",
    "        else:\n",
    "            thresholds.append(np.quantile(np.array(hist), q))\n",
    "        hist.append(v if np.isfinite(v) else 0.0)\n",
    "    return pd.Series(thresholds, index=prob.index)\n",
    "\n",
    "\n",
    "def evaluate(prob_df: pd.DataFrame, labs: pd.DataFrame,\n",
    "             target_col_prob: str, target_event_col: str, budget_per_year: int,\n",
    "             restrict_summer_4cp: bool = False) -> dict:\n",
    "    labs_idx = labs.set_index(\"date\").sort_index()\n",
    "    idx = prob_df.index\n",
    "\n",
    "    if restrict_summer_4cp:\n",
    "        mask = labs_idx.loc[idx, \"is_4cp_month\"] == 1\n",
    "        idx = idx[mask.values]\n",
    "        if len(idx) == 0:\n",
    "            return {\"brier\": np.nan, \"precision\": np.nan, \"recall\": np.nan, \"f1\": np.nan, \"auc\": np.nan}\n",
    "\n",
    "    y = labs_idx.loc[idx, target_event_col].astype(int).values\n",
    "    p = prob_df.loc[idx, target_col_prob].values\n",
    "    p = np.nan_to_num(p, nan=0.0)\n",
    "\n",
    "    brier = brier_score_loss(y, p)\n",
    "    thr = adaptive_threshold_series(pd.Series(p, index=idx), budget_per_year)\n",
    "    alerts = (pd.Series(p, index=idx) >= thr).astype(int).values\n",
    "\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y, alerts, average='binary', zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y, p)\n",
    "    except Exception:\n",
    "        auc = np.nan\n",
    "\n",
    "    return {\"brier\": float(brier), \"precision\": float(prec), \"recall\": float(rec),\n",
    "            \"f1\": float(f1), \"auc\": float(auc)}\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T18:29:34.536604Z",
     "start_time": "2025-08-28T18:29:34.533878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== NEW: Alert layer aligned with the paper's examples ====\n",
    "def fixed_threshold_signal(p: pd.Series, thr: float = 0.5) -> pd.Series:\n",
    "    \"\"\"Binary alert: 1 if p >= thr else 0 (default thr=0.5).\"\"\"\n",
    "    return (p >= thr).astype(int)\n",
    "\n",
    "\n",
    "def traffic_light_band(p: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    RED    : p >= 0.80\n",
    "    ORANGE : 0.60 <= p < 0.80\n",
    "    YELLOW : 0.40 <= p < 0.60\n",
    "    GREEN  : p < 0.40\n",
    "    \"\"\"\n",
    "    cats = pd.Series(index=p.index, dtype=\"object\")\n",
    "    cats[p >= 0.80] = \"RED\"\n",
    "    cats[(p >= 0.60) & (p < 0.80)] = \"ORANGE\"\n",
    "    cats[(p >= 0.40) & (p < 0.60)] = \"YELLOW\"\n",
    "    cats[p < 0.40] = \"GREEN\"\n",
    "    return cats\n",
    "\n",
    "# example: attach signals to your probability table\n",
    "# prob_hourly = scenario_probabilities_pjm_hourly(...)\n",
    "# prob_hourly[\"sig_1cp_bin_0p5\"]   = fixed_threshold_signal(prob_hourly[\"p_1cp_hourly_summer\"], 0.5)\n",
    "# prob_hourly[\"sig_1cp_band\"]      = traffic_light_band(prob_hourly[\"p_1cp_hourly_summer\"])\n",
    "# prob_hourly[\"sig_top5_bin_0p5\"]  = fixed_threshold_signal(prob_hourly[\"p_top5_hourly_summer\"], 0.5)\n",
    "# prob_hourly[\"sig_top5_band\"]     = traffic_light_band(prob_hourly[\"p_top5_hourly_summer\"])\n"
   ],
   "id": "d59bc1c98e98040e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T18:29:41.982710Z",
     "start_time": "2025-08-28T18:29:34.543001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== Cell 9 (UPDATED): +4CP (monthly Top-4) hourly & daily ====\n",
    "from sklearn.metrics import precision_recall_fscore_support, brier_score_loss, roc_auc_score\n",
    "\n",
    "\n",
    "def _eval_binary(y_true, p_prob, thr=0.5):\n",
    "    y_true = np.asarray(y_true, dtype=int)\n",
    "    p_prob = np.asarray(p_prob, dtype=float)\n",
    "    mask = np.isfinite(y_true) & np.isfinite(p_prob)\n",
    "    if mask.sum() == 0:\n",
    "        return dict(brier=np.nan, precision=np.nan, recall=np.nan, f1=np.nan, auc=np.nan)\n",
    "    y, p = y_true[mask], p_prob[mask]\n",
    "    brier = brier_score_loss(y, p)\n",
    "    y_hat = (p >= thr).astype(int)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y, y_hat, average=\"binary\", zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y, p)\n",
    "    except Exception:\n",
    "        auc = np.nan\n",
    "    return dict(brier=float(brier), precision=float(prec), recall=float(rec), f1=float(f1), auc=float(auc))\n",
    "\n",
    "\n",
    "summary_rows = []\n",
    "probs_by_src = {}\n",
    "labels_by_src = {}\n",
    "\n",
    "for src in FORECAST_SOURCES:\n",
    "    fcols = [c for c in FCAST_COLS if c.startswith(src)]\n",
    "    if not fcols:\n",
    "        print(f\"[WARN] No forecast column for source '{src}', skip.\")\n",
    "        continue\n",
    "    fcol = fcols[0]\n",
    "    print(f\"\\n>>> Running source: {src} — column: {fcol}\")\n",
    "\n",
    "    # 1) 基础小时表\n",
    "    df_base = build_base_df(fcol)\n",
    "\n",
    "    # 2) 逐小时残差 -> 按日的 24 维矩阵（供边缘拟合）\n",
    "    features_hourly = build_hourly_features(df_base)\n",
    "    feats_daily24 = make_hourly_matrix(features_hourly)\n",
    "\n",
    "    # 3) POT-GPD（上尾）+ Graphical LASSO\n",
    "    transforms = fit_marginals_pot(feats_daily24, p_u=0.90, min_tail_n=50)\n",
    "    Z = gaussianize(feats_daily24, transforms)\n",
    "    gl = GraphicalLassoCV()\n",
    "    gl.fit(Z)\n",
    "    cov = gl.covariance_\n",
    "\n",
    "    # 4) 1CP/Top-5（小时口径，夏季）——你已有\n",
    "    prob_hourly = scenario_probabilities_pjm_hourly(\n",
    "        df_base, feats_daily24, transforms, cov,\n",
    "        n_sims=N_SIMS, last_days=LAST_DAYS\n",
    "    )\n",
    "    prob_hourly[\"sig_1cp_bin_0p5\"] = fixed_threshold_signal(prob_hourly[\"p_1cp_hourly_summer\"], 0.5)\n",
    "    prob_hourly[\"sig_1cp_band\"] = traffic_light_band(prob_hourly[\"p_1cp_hourly_summer\"])\n",
    "    prob_hourly[\"sig_top5_bin_0p5\"] = fixed_threshold_signal(prob_hourly[\"p_top5_hourly_summer\"], 0.5)\n",
    "    prob_hourly[\"sig_top5_band\"] = traffic_light_band(prob_hourly[\"p_top5_hourly_summer\"])\n",
    "\n",
    "    # 5) 4CP（每月 Top-4）：同时输出“小时口径 & 日口径”\n",
    "    prob_4cp = scenario_probabilities_pjm_4cp(\n",
    "        df_base, feats_daily24, transforms, cov,\n",
    "        n_sims=N_SIMS, last_days=LAST_DAYS,\n",
    "        return_peak_hour=False\n",
    "    )\n",
    "    prob_4cp[\"sig_4cp_hourly_bin_0p5\"] = fixed_threshold_signal(prob_4cp[\"p_4cp_hourly_monthlyTop4\"], 0.5)\n",
    "    prob_4cp[\"sig_4cp_hourly_band\"] = traffic_light_band(prob_4cp[\"p_4cp_hourly_monthlyTop4\"])\n",
    "    prob_4cp[\"sig_4cp_daily_bin_0p5\"] = fixed_threshold_signal(prob_4cp[\"p_4cp_daily_monthlyTop4\"], 0.5)\n",
    "    prob_4cp[\"sig_4cp_daily_band\"] = traffic_light_band(prob_4cp[\"p_4cp_daily_monthlyTop4\"])\n",
    "\n",
    "    # 合并到一个 per-source 概率表（索引 date 对齐）\n",
    "    prob_all = prob_hourly.join(prob_4cp, how=\"outer\").sort_index()\n",
    "\n",
    "    # 6) 构造评估标签（与 Cell 9 里 1CP/Top-5 一致；新增 4CP 两类标签）\n",
    "    #    先复用你已有的“夏季小时阈值”与“日峰”\n",
    "    thr_summer = compute_pjm_summer_thresholds_hourly(df_base)  # 1CP/Top5 小时口径\n",
    "    day_max_actual = (\n",
    "        df_base.assign(date=df_base[\"timestamp\"].dt.floor(\"D\"))\n",
    "        .groupby(\"date\")[\"actual_mw\"].max()\n",
    "        .to_frame(\"day_max_actual\")\n",
    "    )\n",
    "    labs = thr_summer.join(day_max_actual, how=\"left\")\n",
    "    labs = labs[labs[\"is_summer_day\"].astype(bool)]\n",
    "\n",
    "    # 1CP/Top5 标签（小时口径，夏季）\n",
    "    labs_1cp = labs[np.isfinite(labs[\"summer_running_max_prev_hourly\"])]\n",
    "    labs_top5 = labs[np.isfinite(labs[\"summer_top5_thr_prev_hourly\"])]\n",
    "    y1 = (labs_1cp[\"day_max_actual\"].values > labs_1cp[\"summer_running_max_prev_hourly\"].values).astype(int)\n",
    "    y5 = (labs_top5[\"day_max_actual\"].values > labs_top5[\"summer_top5_thr_prev_hourly\"].values).astype(int)\n",
    "    p1 = prob_all.reindex(labs_1cp.index)[\"p_1cp_hourly_summer\"].values\n",
    "    p5 = prob_all.reindex(labs_top5.index)[\"p_top5_hourly_summer\"].values\n",
    "\n",
    "    # 4CP 阈值（新增）：每月 Top-4 —— 小时口径 & 日口径\n",
    "    thr4h = compute_summer_monthly_topk_thresholds_hourly(df_base, k=4)\n",
    "    thr4d = compute_summer_monthly_topk_thresholds_daily(df_base, k=4)\n",
    "    # 小时口径 4CP：当日“任一小时”是不是超过本月到昨日为止的第4高“小时”阈值 → 等价于 day_max_actual > m4_hourly_prev\n",
    "    labs_4h = thr4h.join(day_max_actual, how=\"left\")\n",
    "    labs_4h = labs_4h[labs_4h[\"is_summer_month_day\"].astype(bool)]\n",
    "    y4h = (labs_4h[\"day_max_actual\"].values > labs_4h[\"m4_hourly_prev\"].values).astype(int)\n",
    "    p4h = prob_all.reindex(labs_4h.index)[\"p_4cp_hourly_monthlyTop4\"].values\n",
    "\n",
    "    # 日口径 4CP：当日“日峰”是不是超过本月到昨日为止的第4高“日峰”阈值\n",
    "    labs_4d = thr4d.join(day_max_actual, how=\"left\")\n",
    "    labs_4d = labs_4d[labs_4d[\"is_summer_month_day\"].astype(bool)]\n",
    "    y4d = (labs_4d[\"day_max_actual\"].values > labs_4d[\"m4_daily_prev\"].values).astype(int)\n",
    "    p4d = prob_all.reindex(labs_4d.index)[\"p_4cp_daily_monthlyTop4\"].values\n",
    "\n",
    "    # 7) 评估（固定阈值 0.5）\n",
    "    m1 = _eval_binary(y1, p1, thr=0.5)\n",
    "    m5 = _eval_binary(y5, p5, thr=0.5)\n",
    "    m4h = _eval_binary(y4h, p4h, thr=0.5)\n",
    "    m4d = _eval_binary(y4d, p4d, thr=0.5)\n",
    "\n",
    "    # 8) 汇总与持久化\n",
    "    probs_by_src[src] = prob_all.copy()\n",
    "    # 把 4CP 标签一并存放，便于 Cell 10 校准曲线\n",
    "    labels_by_src[src] = (labs.copy()\n",
    "                          .join(labs_4h[[\"m4_hourly_prev\"]], how=\"outer\")\n",
    "                          .join(labs_4d[[\"m4_daily_prev\"]], how=\"outer\"))\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"forecast_src\": src,\n",
    "        # 1CP hourly (summer)\n",
    "        \"1CP_hourly_brier\": m1[\"brier\"],\n",
    "        \"1CP_hourly_prec@0.5\": m1[\"precision\"],\n",
    "        \"1CP_hourly_rec@0.5\": m1[\"recall\"],\n",
    "        \"1CP_hourly_f1@0.5\": m1[\"f1\"],\n",
    "        \"1CP_hourly_auc\": m1[\"auc\"],\n",
    "        # Top-5 hourly (summer)\n",
    "        \"Top5_hourly_brier\": m5[\"brier\"],\n",
    "        \"Top5_hourly_prec@0.5\": m5[\"precision\"],\n",
    "        \"Top5_hourly_rec@0.5\": m5[\"recall\"],\n",
    "        \"Top5_hourly_f1@0.5\": m5[\"f1\"],\n",
    "        \"Top5_hourly_auc\": m5[\"auc\"],\n",
    "        # 4CP hourly (monthly Top-4)\n",
    "        \"4CP_hourly_brier\": m4h[\"brier\"],\n",
    "        \"4CP_hourly_prec@0.5\": m4h[\"precision\"],\n",
    "        \"4CP_hourly_rec@0.5\": m4h[\"recall\"],\n",
    "        \"4CP_hourly_f1@0.5\": m4h[\"f1\"],\n",
    "        \"4CP_hourly_auc\": m4h[\"auc\"],\n",
    "        # 4CP daily  (monthly Top-4)\n",
    "        \"4CP_daily_brier\": m4d[\"brier\"],\n",
    "        \"4CP_daily_prec@0.5\": m4d[\"precision\"],\n",
    "        \"4CP_daily_rec@0.5\": m4d[\"recall\"],\n",
    "        \"4CP_daily_f1@0.5\": m4d[\"f1\"],\n",
    "        \"4CP_daily_auc\": m4d[\"auc\"],\n",
    "        # band counts\n",
    "        \"cnt_RED_4CP_hourly\": int((prob_all[\"sig_4cp_hourly_band\"] == \"RED\").sum()),\n",
    "        \"cnt_ORANGE_4CP_hourly\": int((prob_all[\"sig_4cp_hourly_band\"] == \"ORANGE\").sum()),\n",
    "        \"cnt_YELLOW_4CP_hourly\": int((prob_all[\"sig_4cp_hourly_band\"] == \"YELLOW\").sum()),\n",
    "        \"cnt_GREEN_4CP_hourly\": int((prob_all[\"sig_4cp_hourly_band\"] == \"GREEN\").sum()),\n",
    "        \"cnt_RED_4CP_daily\": int((prob_all[\"sig_4cp_daily_band\"] == \"RED\").sum()),\n",
    "        \"cnt_ORANGE_4CP_daily\": int((prob_all[\"sig_4cp_daily_band\"] == \"ORANGE\").sum()),\n",
    "        \"cnt_YELLOW_4CP_daily\": int((prob_all[\"sig_4cp_daily_band\"] == \"YELLOW\").sum()),\n",
    "        \"cnt_GREEN_4CP_daily\": int((prob_all[\"sig_4cp_daily_band\"] == \"GREEN\").sum()),\n",
    "    })\n",
    "\n",
    "    if 'SAVE_OUTPUTS' in globals() and SAVE_OUTPUTS:\n",
    "        out_csv = os.path.join(OUT_DIR, f\"prob_hourly_pjm_{src}.csv\")\n",
    "        probs_by_src[src].to_csv(out_csv)\n",
    "        print(\"Saved:\", out_csv)\n",
    "\n",
    "# 总结表\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values(\"forecast_src\").reset_index(drop=True)\n",
    "display(summary_df)\n",
    "if 'SAVE_OUTPUTS' in globals() and SAVE_OUTPUTS:\n",
    "    out_summary = os.path.join(OUT_DIR, \"summary_pjm_hourly_cp_metrics.csv\")\n",
    "    summary_df.to_csv(out_summary, index=False)\n",
    "    print(\"Saved:\", out_summary)\n"
   ],
   "id": "4fc954b95ac2b2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Running source: ECA — column: ECA: IESO-Ontario Demand Historic Forecast\n",
      "Saved: ./output_cp_prob_mc_ieso\\prob_hourly_pjm_ECA.csv\n",
      "\n",
      ">>> Running source: RTO — column: RTO: IESO-Ontario Demand Historic Forecast\n",
      "Saved: ./output_cp_prob_mc_ieso\\prob_hourly_pjm_RTO.csv\n",
      "\n",
      ">>> Running source: TESLA — column: TESLA: IESO-Ontario Demand Historic Forecast\n",
      "Saved: ./output_cp_prob_mc_ieso\\prob_hourly_pjm_TESLA.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  forecast_src  1CP_hourly_brier  1CP_hourly_prec@0.5  1CP_hourly_rec@0.5  \\\n",
       "0          ECA          0.027098             1.000000            0.111111   \n",
       "1          RTO          0.009783             0.666667            0.888889   \n",
       "2        TESLA          0.009783             0.666667            0.888889   \n",
       "\n",
       "   1CP_hourly_f1@0.5  1CP_hourly_auc  Top5_hourly_brier  Top5_hourly_prec@0.5  \\\n",
       "0           0.200000        0.949690           0.030127              1.000000   \n",
       "1           0.761905        0.997616           0.018470              0.733333   \n",
       "2           0.761905        0.997616           0.018470              0.733333   \n",
       "\n",
       "   Top5_hourly_rec@0.5  Top5_hourly_f1@0.5  Top5_hourly_auc  4CP_hourly_brier  \\\n",
       "0             0.166667            0.285714         0.959601          0.077302   \n",
       "1             0.916667            0.814815         0.992391          0.037999   \n",
       "2             0.916667            0.814815         0.992391          0.037999   \n",
       "\n",
       "   4CP_hourly_prec@0.5  4CP_hourly_rec@0.5  4CP_hourly_f1@0.5  4CP_hourly_auc  \\\n",
       "0             0.916667            0.314286           0.468085        0.926581   \n",
       "1             0.815789            0.885714           0.849315        0.985288   \n",
       "2             0.815789            0.885714           0.849315        0.985288   \n",
       "\n",
       "   4CP_daily_brier  4CP_daily_prec@0.5  4CP_daily_rec@0.5  4CP_daily_f1@0.5  \\\n",
       "0         0.122097            0.714286           0.471698          0.568182   \n",
       "1         0.055429            0.854545           0.886792          0.870370   \n",
       "2         0.055429            0.854545           0.886792          0.870370   \n",
       "\n",
       "   4CP_daily_auc  cnt_RED_4CP_hourly  cnt_ORANGE_4CP_hourly  \\\n",
       "0       0.853151                   9                      2   \n",
       "1       0.974605                  32                      4   \n",
       "2       0.974605                  32                      4   \n",
       "\n",
       "   cnt_YELLOW_4CP_hourly  cnt_GREEN_4CP_hourly  cnt_RED_4CP_daily  \\\n",
       "0                      3                   222                 17   \n",
       "1                      5                   195                 45   \n",
       "2                      5                   195                 45   \n",
       "\n",
       "   cnt_ORANGE_4CP_daily  cnt_YELLOW_4CP_daily  cnt_GREEN_4CP_daily  \n",
       "0                    11                    19                  165  \n",
       "1                     8                     4                  155  \n",
       "2                     8                     4                  155  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_src</th>\n",
       "      <th>1CP_hourly_brier</th>\n",
       "      <th>1CP_hourly_prec@0.5</th>\n",
       "      <th>1CP_hourly_rec@0.5</th>\n",
       "      <th>1CP_hourly_f1@0.5</th>\n",
       "      <th>1CP_hourly_auc</th>\n",
       "      <th>Top5_hourly_brier</th>\n",
       "      <th>Top5_hourly_prec@0.5</th>\n",
       "      <th>Top5_hourly_rec@0.5</th>\n",
       "      <th>Top5_hourly_f1@0.5</th>\n",
       "      <th>Top5_hourly_auc</th>\n",
       "      <th>4CP_hourly_brier</th>\n",
       "      <th>4CP_hourly_prec@0.5</th>\n",
       "      <th>4CP_hourly_rec@0.5</th>\n",
       "      <th>4CP_hourly_f1@0.5</th>\n",
       "      <th>4CP_hourly_auc</th>\n",
       "      <th>4CP_daily_brier</th>\n",
       "      <th>4CP_daily_prec@0.5</th>\n",
       "      <th>4CP_daily_rec@0.5</th>\n",
       "      <th>4CP_daily_f1@0.5</th>\n",
       "      <th>4CP_daily_auc</th>\n",
       "      <th>cnt_RED_4CP_hourly</th>\n",
       "      <th>cnt_ORANGE_4CP_hourly</th>\n",
       "      <th>cnt_YELLOW_4CP_hourly</th>\n",
       "      <th>cnt_GREEN_4CP_hourly</th>\n",
       "      <th>cnt_RED_4CP_daily</th>\n",
       "      <th>cnt_ORANGE_4CP_daily</th>\n",
       "      <th>cnt_YELLOW_4CP_daily</th>\n",
       "      <th>cnt_GREEN_4CP_daily</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECA</td>\n",
       "      <td>0.027098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.949690</td>\n",
       "      <td>0.030127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.959601</td>\n",
       "      <td>0.077302</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.926581</td>\n",
       "      <td>0.122097</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.853151</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RTO</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.997616</td>\n",
       "      <td>0.018470</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.992391</td>\n",
       "      <td>0.037999</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.985288</td>\n",
       "      <td>0.055429</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.974605</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>195</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TESLA</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.997616</td>\n",
       "      <td>0.018470</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.992391</td>\n",
       "      <td>0.037999</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.985288</td>\n",
       "      <td>0.055429</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.974605</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>195</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./output_cp_prob_mc_ieso\\summary_pjm_hourly_cp_metrics.csv\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "4b9fd6ce",
   "metadata": {},
   "source": "## 6. Visualization"
  },
  {
   "cell_type": "code",
   "id": "92bc6176",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T18:29:46.718732Z",
     "start_time": "2025-08-28T18:29:42.066866Z"
    }
   },
   "source": [
    "# ==== Cell 10: Visualization (PJM summer, hourly CP, traffic-light bands) ====\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "\n",
    "# ---------- helpers ----------\n",
    "\n",
    "def _band_color(band: str) -> str:\n",
    "    return {\n",
    "        \"RED\": \"#d62728\",\n",
    "        \"ORANGE\": \"#ff7f0e\",\n",
    "        \"YELLOW\": \"#bcbd22\",\n",
    "        \"GREEN\": \"#2ca02c\"\n",
    "    }.get(str(band), \"#7f7f7f\")\n",
    "\n",
    "\n",
    "def _ensure_dir(path: str):\n",
    "    d = os.path.dirname(path)\n",
    "    if d and not os.path.exists(d):\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "\n",
    "def plot_prob_timeseries(prob_df: pd.DataFrame, p_col: str, title: str,\n",
    "                         save_path: str | None = None, show: bool = True):\n",
    "    \"\"\"\n",
    "    Timeseries of probability with traffic-light shading and 0.5 decision line.\n",
    "    Supports 1CP / Top-5 / 4CP (hourly & daily).\n",
    "    \"\"\"\n",
    "    if prob_df.empty or p_col not in prob_df.columns:\n",
    "        print(f\"[WARN] plot_prob_timeseries: missing column {p_col}\")\n",
    "        return\n",
    "\n",
    "    # --- 明确映射：概率列 -> 分级列（包含 4CP） ---\n",
    "    BAND_FOR = {\n",
    "        \"p_1cp_hourly_summer\": \"sig_1cp_band\",\n",
    "        \"p_top5_hourly_summer\": \"sig_top5_band\",\n",
    "        \"p_4cp_hourly_monthlyTop4\": \"sig_4cp_hourly_band\",\n",
    "        \"p_4cp_daily_monthlyTop4\": \"sig_4cp_daily_band\",\n",
    "    }\n",
    "    band_col = BAND_FOR.get(p_col, None)\n",
    "\n",
    "    # --- 连续日索引，保留 NaN（让非夏季段断开，不画“斜坡”） ---\n",
    "    idx_min = prob_df.index.min()\n",
    "    idx_max = prob_df.index.max()\n",
    "    if pd.isna(idx_min) or pd.isna(idx_max):\n",
    "        print(f\"[WARN] plot_prob_timeseries: invalid index for {p_col}\")\n",
    "        return\n",
    "    idx = pd.date_range(idx_min, idx_max, freq=\"D\")\n",
    "    p = prob_df[p_col].reindex(idx)  # 不 dropna，NaN 将打断折线\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "\n",
    "    # 背景色带\n",
    "    ax.axhspan(0.80, 1.00, alpha=0.08, color=_band_color(\"RED\"))\n",
    "    ax.axhspan(0.60, 0.80, alpha=0.06, color=_band_color(\"ORANGE\"))\n",
    "    ax.axhspan(0.40, 0.60, alpha=0.05, color=_band_color(\"YELLOW\"))\n",
    "    ax.axhspan(0.00, 0.40, alpha=0.04, color=_band_color(\"GREEN\"))\n",
    "\n",
    "    # 概率曲线（NaN 自动断开）\n",
    "    ax.plot(p.index, p.values, lw=1.5, label=p_col)\n",
    "\n",
    "    # 0.5 决策线\n",
    "    ax.axhline(0.5, ls=\"--\", lw=1, color=\"#444444\", alpha=0.6, label=\"threshold=0.5\")\n",
    "\n",
    "    # 彩色散点（按分级列）\n",
    "    if band_col and band_col in prob_df.columns:\n",
    "        bands = prob_df[band_col].reindex(idx)\n",
    "        finite_mask = np.isfinite(p.values)\n",
    "        for b in [\"RED\", \"ORANGE\", \"YELLOW\", \"GREEN\"]:\n",
    "            mask = (bands == b) & finite_mask\n",
    "            if mask.any():\n",
    "                ax.scatter(p.index[mask], p.values[mask], s=18,\n",
    "                           color=_band_color(b), label=b, zorder=3, alpha=0.9)\n",
    "\n",
    "    ax.set_ylim(0, 1.02)\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Probability\")\n",
    "    ax.grid(True, ls=\":\", alpha=0.35)\n",
    "    # 避免重复图例项\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    uniq = dict(zip(labels, handles))\n",
    "    ax.legend(uniq.values(), uniq.keys(), ncol=5, fontsize=9, frameon=False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        _ensure_dir(save_path)\n",
    "        plt.savefig(save_path, dpi=140, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "    elif show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_band_counts(prob_df: pd.DataFrame, band_col: str, title: str,\n",
    "                     save_path: str | None = None, show: bool = True):\n",
    "    \"\"\"\n",
    "    Bar chart of traffic-light band counts.\n",
    "    \"\"\"\n",
    "    if prob_df.empty or band_col not in prob_df.columns:\n",
    "        print(f\"[WARN] plot_band_counts: missing column {band_col}\")\n",
    "        return\n",
    "\n",
    "    counts = prob_df[band_col].value_counts().reindex([\"RED\", \"ORANGE\", \"YELLOW\", \"GREEN\"]).fillna(0)\n",
    "    fig, ax = plt.subplots(figsize=(8, 3.6))\n",
    "    colors = [_band_color(b) for b in counts.index]\n",
    "    ax.bar(counts.index, counts.values, color=colors)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Days (count)\")\n",
    "    ax.grid(axis=\"y\", ls=\":\", alpha=0.35)\n",
    "    for i, v in enumerate(counts.values):\n",
    "        ax.text(i, v + max(counts.values) * 0.02 if counts.values.max() > 0 else 0.2, f\"{int(v)}\",\n",
    "                ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        _ensure_dir(save_path)\n",
    "        plt.savefig(save_path, dpi=140, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "    elif show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def calibration_curve(prob_df: pd.DataFrame,\n",
    "                      labs_df: pd.DataFrame,\n",
    "                      p_col: str,\n",
    "                      label_kind: str,\n",
    "                      n_bins: int = 10,\n",
    "                      title: str = \"\",\n",
    "                      save_path: str | None = None,\n",
    "                      show: bool = True):\n",
    "    \"\"\"\n",
    "    Reliability / calibration curve.\n",
    "    Supported label_kind: '1cp', 'top5', '4cp_hourly', '4cp_daily'\n",
    "    - 统一按夏季过滤：优先使用 labs_df['is_summer_day']，若无则使用 'is_summer_month_day'\n",
    "    - 阈值列：\n",
    "        1cp        -> 'summer_running_max_prev_hourly'\n",
    "        top5       -> 'summer_top5_thr_prev_hourly'\n",
    "        4cp_hourly -> 'm4_hourly_prev'\n",
    "        4cp_daily  -> 'm4_daily_prev'\n",
    "    \"\"\"\n",
    "    if prob_df.empty or p_col not in prob_df.columns:\n",
    "        print(f\"[WARN] calibration_curve: missing {p_col}\")\n",
    "        return\n",
    "\n",
    "    labs = labs_df.copy()\n",
    "\n",
    "    # 统一的夏季过滤：优先 is_summer_day（1CP/Top-5），否则 is_summer_month_day（4CP）\n",
    "    summer_flag_col = None\n",
    "    if \"is_summer_day\" in labs.columns:\n",
    "        summer_flag_col = \"is_summer_day\"\n",
    "    elif \"is_summer_month_day\" in labs.columns:\n",
    "        summer_flag_col = \"is_summer_month_day\"\n",
    "\n",
    "    if summer_flag_col is not None:\n",
    "        labs = labs[labs[summer_flag_col].astype(bool)]\n",
    "\n",
    "    # 选择阈值和构造标签\n",
    "    if label_kind == \"1cp\":\n",
    "        thr_col = \"summer_running_max_prev_hourly\"\n",
    "        if thr_col not in labs.columns:\n",
    "            print(f\"[WARN] calibration_curve: missing column {thr_col}\")\n",
    "            return\n",
    "        labs = labs[np.isfinite(labs[thr_col])]\n",
    "        y = (labs[\"day_max_actual\"].values > labs[thr_col].values).astype(int)\n",
    "\n",
    "    elif label_kind == \"top5\":\n",
    "        thr_col = \"summer_top5_thr_prev_hourly\"\n",
    "        if thr_col not in labs.columns:\n",
    "            print(f\"[WARN] calibration_curve: missing column {thr_col}\")\n",
    "            return\n",
    "        labs = labs[np.isfinite(labs[thr_col])]\n",
    "        y = (labs[\"day_max_actual\"].values > labs[thr_col].values).astype(int)\n",
    "\n",
    "    elif label_kind == \"4cp_hourly\":\n",
    "        thr_col = \"m4_hourly_prev\"\n",
    "        if thr_col not in labs.columns:\n",
    "            print(f\"[WARN] calibration_curve: missing column {thr_col} for 4cp_hourly\")\n",
    "            return\n",
    "        labs = labs[np.isfinite(labs[thr_col])]\n",
    "        y = (labs[\"day_max_actual\"].values > labs[thr_col].values).astype(int)\n",
    "\n",
    "    elif label_kind == \"4cp_daily\":\n",
    "        thr_col = \"m4_daily_prev\"\n",
    "        if thr_col not in labs.columns:\n",
    "            print(f\"[WARN] calibration_curve: missing column {thr_col} for 4cp_daily\")\n",
    "            return\n",
    "        labs = labs[np.isfinite(labs[thr_col])]\n",
    "        y = (labs[\"day_max_actual\"].values > labs[thr_col].values).astype(int)\n",
    "\n",
    "    else:\n",
    "        print(f\"[WARN] calibration_curve: unknown label_kind={label_kind}\")\n",
    "        return\n",
    "\n",
    "    # 与概率对齐（按日期索引）\n",
    "    df = pd.DataFrame({\n",
    "        \"p\": prob_df.reindex(labs.index)[p_col].values,\n",
    "        \"y\": y\n",
    "    }).dropna()\n",
    "    if df.empty:\n",
    "        print(f\"[WARN] calibration_curve: no aligned data for {p_col} (label_kind={label_kind})\")\n",
    "        return\n",
    "\n",
    "    # 分箱并绘图\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    df[\"bin\"] = pd.cut(df[\"p\"], bins=bins, include_lowest=True)\n",
    "    agg = df.groupby(\"bin\", observed=True).agg(p_mean=(\"p\", \"mean\"), y_rate=(\"y\", \"mean\"), n=(\"y\", \"size\")).dropna()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6.4, 6.0))\n",
    "    ax.plot([0, 1], [0, 1], ls=\"--\", color=\"#444444\", alpha=0.6, label=\"Perfect\")\n",
    "    ax.plot(agg[\"p_mean\"], agg[\"y_rate\"], marker=\"o\", lw=1.5, label=\"Observed\")\n",
    "    for xp, yp, nn in zip(agg[\"p_mean\"], agg[\"y_rate\"], agg[\"n\"]):\n",
    "        ax.text(xp, yp, f\" n={nn}\", fontsize=9, ha=\"left\", va=\"bottom\", alpha=0.75)\n",
    "\n",
    "    ax.set_xlim(0, 1);\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.xaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter(1.0))\n",
    "    ax.set_xlabel(\"Predicted probability\")\n",
    "    ax.set_ylabel(\"Observed frequency\")\n",
    "    ax.set_title(title if title else f\"Calibration — {p_col} ({label_kind})\")\n",
    "    ax.grid(True, ls=\":\", alpha=0.35)\n",
    "    ax.legend(frameon=False)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        _ensure_dir(save_path)\n",
    "        plt.savefig(save_path, dpi=140, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "    elif show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ---------- per-source plots ----------\n",
    "if not probs_by_src:\n",
    "    print(\"[WARN] probs_by_src is empty — run Cell 9 first.\")\n",
    "else:\n",
    "    for src, prob in probs_by_src.items():\n",
    "        # 1) 原有：1CP / Top-5\n",
    "        plot_prob_timeseries(\n",
    "            prob_df=prob, p_col=\"p_1cp_hourly_summer\",\n",
    "            title=f\"{src} — 1CP (Hourly, Summer) Probability\",\n",
    "            save_path=(os.path.join(OUT_DIR, f\"ts_1cp_hourly_{src}.png\") if (\n",
    "                    'SAVE_OUTPUTS' in globals() and SAVE_OUTPUTS) else None),\n",
    "            show=('SAVE_OUTPUTS' in globals() and not SAVE_OUTPUTS))\n",
    "        plot_prob_timeseries(\n",
    "            prob_df=prob, p_col=\"p_top5_hourly_summer\",\n",
    "            title=f\"{src} — Top-5 (Hourly, Summer) Probability\",\n",
    "            save_path=(os.path.join(OUT_DIR, f\"ts_top5_hourly_{src}.png\") if (\n",
    "                    'SAVE_OUTPUTS' in globals() and SAVE_OUTPUTS) else None),\n",
    "            show=('SAVE_OUTPUTS' in globals() and not SAVE_OUTPUTS))\n",
    "\n",
    "        # 2) 新增：4CP（小时口径 / 日口径）\n",
    "        plot_prob_timeseries(\n",
    "            prob_df=prob, p_col=\"p_4cp_hourly_monthlyTop4\",\n",
    "            title=f\"{src} — 4CP (Hourly, Monthly Top-4, Jun–Sep) Probability\",\n",
    "            save_path=(os.path.join(OUT_DIR, f\"ts_4cp_hourly_{src}.png\") if (\n",
    "                    'SAVE_OUTPUTS' in globals() and SAVE_OUTPUTS) else None),\n",
    "            show=('SAVE_OUTPUTS' in globals() and not SAVE_OUTPUTS))\n",
    "        plot_prob_timeseries(\n",
    "            prob_df=prob, p_col=\"p_4cp_daily_monthlyTop4\",\n",
    "            title=f\"{src} — 4CP (Daily,  Monthly Top-4, Jun–Sep) Probability\",\n",
    "            save_path=(os.path.join(OUT_DIR, f\"ts_4cp_daily_{src}.png\") if (\n",
    "                    'SAVE_OUTPUTS' in globals() and SAVE_OUTPUTS) else None),\n",
    "            show=('SAVE_OUTPUTS' in globals() and not SAVE_OUTPUTS))\n",
    "\n",
    "        # 3) 分级计数柱状图\n",
    "        plot_band_counts(\n",
    "            prob_df=prob, band_col=\"sig_4cp_hourly_band\",\n",
    "            title=f\"{src} — 4CP Hourly Traffic-Light Counts\",\n",
    "            save_path=(os.path.join(OUT_DIR, f\"band_counts_4cp_hourly_{src}.png\") if (\n",
    "                    'SAVE_OUTPUTS' in globals() and SAVE_OUTPUTS) else None),\n",
    "            show=('SAVE_OUTPUTS' in globals() and not SAVE_OUTPUTS))\n",
    "        plot_band_counts(\n",
    "            prob_df=prob, band_col=\"sig_4cp_daily_band\",\n",
    "            title=f\"{src} — 4CP Daily Traffic-Light Counts\",\n",
    "            save_path=(os.path.join(OUT_DIR, f\"band_counts_4cp_daily_{src}.png\") if (\n",
    "                    'SAVE_OUTPUTS' in globals() and SAVE_OUTPUTS) else None),\n",
    "            show=('SAVE_OUTPUTS' in globals() and not SAVE_OUTPUTS))\n",
    "\n",
    "        # 4) 校准曲线（需要 Cell 9 里把 4CP 标签列加入 labels_by_src）\n",
    "        if src in labels_by_src:\n",
    "            labs = labels_by_src[src]\n",
    "            # 1CP / Top-5（原有）\n",
    "            calibration_curve(\n",
    "                prob_df=prob, labs_df=labs,\n",
    "                p_col=\"p_1cp_hourly_summer\", label_kind=\"1cp\",\n",
    "                n_bins=10,\n",
    "                title=f\"{src} — Calibration (1CP Hourly, Summer)\",\n",
    "                save_path=(os.path.join(OUT_DIR, f\"calib_1cp_{src}.png\") if (\n",
    "                        'SAVE_OUTPUTS' in globals() and SAVE_OUTPUTS) else None),\n",
    "                show=('SAVE_OUTPUTS' in globals() and not SAVE_OUTPUTS))\n",
    "            calibration_curve(\n",
    "                prob_df=prob, labs_df=labs,\n",
    "                p_col=\"p_top5_hourly_summer\", label_kind=\"top5\",\n",
    "                n_bins=10,\n",
    "                title=f\"{src} — Calibration (Top-5 Hourly, Summer)\",\n",
    "                save_path=(os.path.join(OUT_DIR, f\"calib_top5_{src}.png\") if (\n",
    "                        'SAVE_OUTPUTS' in globals() and SAVE_OUTPUTS) else None),\n",
    "                show=('SAVE_OUTPUTS' in globals() and not SAVE_OUTPUTS))\n",
    "            # 4CP（新增）\n",
    "            calibration_curve(\n",
    "                prob_df=prob, labs_df=labs,\n",
    "                p_col=\"p_4cp_hourly_monthlyTop4\", label_kind=\"4cp_hourly\",\n",
    "                n_bins=10,\n",
    "                title=f\"{src} — Calibration (4CP Hourly, Monthly Top-4)\",\n",
    "                save_path=(os.path.join(OUT_DIR, f\"calib_4cp_hourly_{src}.png\") if (\n",
    "                        'SAVE_OUTPUTS' in globals() and SAVE_OUTPUTS) else None),\n",
    "                show=('SAVE_OUTPUTS' in globals() and not SAVE_OUTPUTS))\n",
    "            calibration_curve(\n",
    "                prob_df=prob, labs_df=labs,\n",
    "                p_col=\"p_4cp_daily_monthlyTop4\", label_kind=\"4cp_daily\",\n",
    "                n_bins=10,\n",
    "                title=f\"{src} — Calibration (4CP Daily,  Monthly Top-4)\",\n",
    "                save_path=(os.path.join(OUT_DIR, f\"calib_4cp_daily_{src}.png\") if (\n",
    "                        'SAVE_OUTPUTS' in globals() and SAVE_OUTPUTS) else None),\n",
    "                show=('SAVE_OUTPUTS' in globals() and not SAVE_OUTPUTS))\n",
    "        else:\n",
    "            print(f\"[INFO] No labels_by_src for {src}; skip 4CP calibration plots.\")\n",
    "\n",
    "# ---------- optional: show summary table again ----------\n",
    "try:\n",
    "    display(summary_df)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Cell 10 complete.\")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  forecast_src  1CP_hourly_brier  1CP_hourly_prec@0.5  1CP_hourly_rec@0.5  \\\n",
       "0          ECA          0.027098             1.000000            0.111111   \n",
       "1          RTO          0.009783             0.666667            0.888889   \n",
       "2        TESLA          0.009783             0.666667            0.888889   \n",
       "\n",
       "   1CP_hourly_f1@0.5  1CP_hourly_auc  Top5_hourly_brier  Top5_hourly_prec@0.5  \\\n",
       "0           0.200000        0.949690           0.030127              1.000000   \n",
       "1           0.761905        0.997616           0.018470              0.733333   \n",
       "2           0.761905        0.997616           0.018470              0.733333   \n",
       "\n",
       "   Top5_hourly_rec@0.5  Top5_hourly_f1@0.5  Top5_hourly_auc  4CP_hourly_brier  \\\n",
       "0             0.166667            0.285714         0.959601          0.077302   \n",
       "1             0.916667            0.814815         0.992391          0.037999   \n",
       "2             0.916667            0.814815         0.992391          0.037999   \n",
       "\n",
       "   4CP_hourly_prec@0.5  4CP_hourly_rec@0.5  4CP_hourly_f1@0.5  4CP_hourly_auc  \\\n",
       "0             0.916667            0.314286           0.468085        0.926581   \n",
       "1             0.815789            0.885714           0.849315        0.985288   \n",
       "2             0.815789            0.885714           0.849315        0.985288   \n",
       "\n",
       "   4CP_daily_brier  4CP_daily_prec@0.5  4CP_daily_rec@0.5  4CP_daily_f1@0.5  \\\n",
       "0         0.122097            0.714286           0.471698          0.568182   \n",
       "1         0.055429            0.854545           0.886792          0.870370   \n",
       "2         0.055429            0.854545           0.886792          0.870370   \n",
       "\n",
       "   4CP_daily_auc  cnt_RED_4CP_hourly  cnt_ORANGE_4CP_hourly  \\\n",
       "0       0.853151                   9                      2   \n",
       "1       0.974605                  32                      4   \n",
       "2       0.974605                  32                      4   \n",
       "\n",
       "   cnt_YELLOW_4CP_hourly  cnt_GREEN_4CP_hourly  cnt_RED_4CP_daily  \\\n",
       "0                      3                   222                 17   \n",
       "1                      5                   195                 45   \n",
       "2                      5                   195                 45   \n",
       "\n",
       "   cnt_ORANGE_4CP_daily  cnt_YELLOW_4CP_daily  cnt_GREEN_4CP_daily  \n",
       "0                    11                    19                  165  \n",
       "1                     8                     4                  155  \n",
       "2                     8                     4                  155  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_src</th>\n",
       "      <th>1CP_hourly_brier</th>\n",
       "      <th>1CP_hourly_prec@0.5</th>\n",
       "      <th>1CP_hourly_rec@0.5</th>\n",
       "      <th>1CP_hourly_f1@0.5</th>\n",
       "      <th>1CP_hourly_auc</th>\n",
       "      <th>Top5_hourly_brier</th>\n",
       "      <th>Top5_hourly_prec@0.5</th>\n",
       "      <th>Top5_hourly_rec@0.5</th>\n",
       "      <th>Top5_hourly_f1@0.5</th>\n",
       "      <th>Top5_hourly_auc</th>\n",
       "      <th>4CP_hourly_brier</th>\n",
       "      <th>4CP_hourly_prec@0.5</th>\n",
       "      <th>4CP_hourly_rec@0.5</th>\n",
       "      <th>4CP_hourly_f1@0.5</th>\n",
       "      <th>4CP_hourly_auc</th>\n",
       "      <th>4CP_daily_brier</th>\n",
       "      <th>4CP_daily_prec@0.5</th>\n",
       "      <th>4CP_daily_rec@0.5</th>\n",
       "      <th>4CP_daily_f1@0.5</th>\n",
       "      <th>4CP_daily_auc</th>\n",
       "      <th>cnt_RED_4CP_hourly</th>\n",
       "      <th>cnt_ORANGE_4CP_hourly</th>\n",
       "      <th>cnt_YELLOW_4CP_hourly</th>\n",
       "      <th>cnt_GREEN_4CP_hourly</th>\n",
       "      <th>cnt_RED_4CP_daily</th>\n",
       "      <th>cnt_ORANGE_4CP_daily</th>\n",
       "      <th>cnt_YELLOW_4CP_daily</th>\n",
       "      <th>cnt_GREEN_4CP_daily</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ECA</td>\n",
       "      <td>0.027098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.949690</td>\n",
       "      <td>0.030127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.959601</td>\n",
       "      <td>0.077302</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.926581</td>\n",
       "      <td>0.122097</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.853151</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RTO</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.997616</td>\n",
       "      <td>0.018470</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.992391</td>\n",
       "      <td>0.037999</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.985288</td>\n",
       "      <td>0.055429</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.974605</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>195</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TESLA</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.997616</td>\n",
       "      <td>0.018470</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.992391</td>\n",
       "      <td>0.037999</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.985288</td>\n",
       "      <td>0.055429</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.974605</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>195</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 10 complete.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T18:37:24.105030Z",
     "start_time": "2025-08-28T18:37:24.085496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def _confusion_counts(y_true: np.ndarray, y_pred: np.ndarray) -> dict:\n",
    "    y_true = y_true.astype(int)\n",
    "    y_pred = y_pred.astype(int)\n",
    "    TP = int(((y_true == 1) & (y_pred == 1)).sum())\n",
    "    FP = int(((y_true == 0) & (y_pred == 1)).sum())\n",
    "    TN = int(((y_true == 0) & (y_pred == 0)).sum())\n",
    "    FN = int(((y_true == 1) & (y_pred == 0)).sum())\n",
    "    return dict(TP=TP, FP=FP, TN=TN, FN=FN)\n",
    "\n",
    "\n",
    "rows = []\n",
    "missing_sources = []\n",
    "\n",
    "needed_prob_cols = {\n",
    "    \"4cp_hourly\": \"p_4cp_hourly_monthlyTop4\",\n",
    "    \"4cp_daily\": \"p_4cp_daily_monthlyTop4\"\n",
    "}\n",
    "\n",
    "for src in FORECAST_SOURCES:\n",
    "    if src not in probs_by_src or src not in labels_by_src:\n",
    "        missing_sources.append(src)\n",
    "        continue\n",
    "    prob_df = probs_by_src[src]\n",
    "    lab_df = labels_by_src[src]\n",
    "\n",
    "    # day_max_actual\n",
    "    if \"day_max_actual\" not in lab_df.columns:\n",
    "        print(f\"[WARN] {src}: 缺少 day_max_actual，跳过。\")\n",
    "        continue\n",
    "\n",
    "    for kind, p_col in needed_prob_cols.items():\n",
    "        thr_col = \"m4_hourly_prev\" if kind == \"4cp_hourly\" else \"m4_daily_prev\"\n",
    "        if p_col not in prob_df.columns:\n",
    "            print(f\"[WARN] {src}: Missing probability column {p_col}, skip {kind}\")\n",
    "            continue\n",
    "        if thr_col not in lab_df.columns:\n",
    "            print(f\"[WARN] {src}: Missing threshold column {thr_col}, skip {kind}\")\n",
    "            continue\n",
    "\n",
    "        # 对齐索引\n",
    "        idx = (prob_df.index\n",
    "               .intersection(lab_df.index))\n",
    "        # 过滤有效标签\n",
    "        mask_valid = (\n",
    "                lab_df.loc[idx, thr_col].replace([np.inf, -np.inf], np.nan).notna()\n",
    "                & lab_df.loc[idx, \"day_max_actual\"].replace([np.inf, -np.inf], np.nan).notna()\n",
    "                & prob_df.loc[idx, p_col].replace([np.inf, -np.inf], np.nan).notna()\n",
    "        )\n",
    "        idx_use = idx[mask_valid]\n",
    "\n",
    "        if len(idx_use) == 0:\n",
    "            print(f\"[INFO] {src}: {kind} No valid sample.\")\n",
    "            continue\n",
    "\n",
    "        y_true = (lab_df.loc[idx_use, \"day_max_actual\"].values >\n",
    "                  lab_df.loc[idx_use, thr_col].values).astype(int)\n",
    "        y_pred = (prob_df.loc[idx_use, p_col].values >= 0.5).astype(int)\n",
    "\n",
    "        cm = _confusion_counts(y_true, y_pred)\n",
    "        cm.update({\n",
    "            \"forecast_src\": src,\n",
    "            \"kind\": kind,\n",
    "            \"support\": int(len(idx_use)),\n",
    "            \"pred_pos\": int(y_pred.sum()),\n",
    "            \"actual_pos\": int(y_true.sum())\n",
    "        })\n",
    "        rows.append(cm)\n",
    "\n",
    "confmat_df = pd.DataFrame(rows).sort_values([\"forecast_src\", \"kind\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"4CP (hourly & daily) Confusion:\")\n",
    "display(confmat_df)\n",
    "\n",
    "if 'SAVE_OUTPUTS' in globals() and SAVE_OUTPUTS:\n",
    "    out_path = os.path.join(OUT_DIR, \"confusion_4cp_hourly_daily.csv\")\n",
    "    confmat_df.to_csv(out_path, index=False)\n",
    "    print(\"Saved:\", out_path)\n",
    "\n",
    "if missing_sources:\n",
    "    print(\"The following sources lack probability or labels and are not involved in statistics:\",\n",
    "          \", \".join(missing_sources))"
   ],
   "id": "dbbe6aa10d491577",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4CP (hourly & daily) Confusion:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   TP  FP   TN  FN forecast_src        kind  support  pred_pos  actual_pos\n",
       "0  25  10  149  28          ECA   4cp_daily      212        35          53\n",
       "1  11   1  200  24          ECA  4cp_hourly      236        12          35\n",
       "2  47   8  151   6          RTO   4cp_daily      212        55          53\n",
       "3  31   7  194   4          RTO  4cp_hourly      236        38          35\n",
       "4  47   8  151   6        TESLA   4cp_daily      212        55          53\n",
       "5  31   7  194   4        TESLA  4cp_hourly      236        38          35"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>forecast_src</th>\n",
       "      <th>kind</th>\n",
       "      <th>support</th>\n",
       "      <th>pred_pos</th>\n",
       "      <th>actual_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>149</td>\n",
       "      <td>28</td>\n",
       "      <td>ECA</td>\n",
       "      <td>4cp_daily</td>\n",
       "      <td>212</td>\n",
       "      <td>35</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>24</td>\n",
       "      <td>ECA</td>\n",
       "      <td>4cp_hourly</td>\n",
       "      <td>236</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>151</td>\n",
       "      <td>6</td>\n",
       "      <td>RTO</td>\n",
       "      <td>4cp_daily</td>\n",
       "      <td>212</td>\n",
       "      <td>55</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>4</td>\n",
       "      <td>RTO</td>\n",
       "      <td>4cp_hourly</td>\n",
       "      <td>236</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>151</td>\n",
       "      <td>6</td>\n",
       "      <td>TESLA</td>\n",
       "      <td>4cp_daily</td>\n",
       "      <td>212</td>\n",
       "      <td>55</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "      <td>4</td>\n",
       "      <td>TESLA</td>\n",
       "      <td>4cp_hourly</td>\n",
       "      <td>236</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./output_cp_prob_mc_ieso\\confusion_4cp_hourly_daily.csv\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
